{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27133c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train / Validation / Test split completed.\n"
     ]
    }
   ],
   "source": [
    "##folder structures and directory\n",
    "RAW_DIR = \"data/raw\"\n",
    "OUT_DIR = \"data\"\n",
    "\n",
    "##splitting ratio\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "##Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "##Identify class labels\n",
    "item_list=os.listdir(RAW_DIR)\n",
    "\n",
    "##Folder names become class labels\n",
    "##keeps only folders [\"apple\", \"mango\", \"grapes\", \"potato\"]\n",
    "classes = [cls for cls in item_list if os.path.isdir(os.path.join(RAW_DIR, cls))] \n",
    "\n",
    "# Create directory structure\n",
    "##Create output directory structure\n",
    " ##Iterates over dataset splits\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    ##Iterates over class labels\n",
    "    for clss in classes:\n",
    "        os.makedirs(os.path.join(OUT_DIR, split, clss), exist_ok=True) #Creates directories\n",
    "\n",
    "# Split per class\n",
    "#Process one class at a time\n",
    "#This ensures class-wise stratification\n",
    "for cls in classes:\n",
    "    #full path to one class folder like data/raw/apple\n",
    "    cls_path = os.path.join(RAW_DIR, cls)\n",
    "    #Collects only image files\n",
    "    images = [f for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))]\n",
    "\n",
    "    random.shuffle(images)\n",
    "\n",
    "    #Compute split sizes\n",
    "    n_total = len(images)\n",
    "    n_train = int(TRAIN_RATIO * n_total)\n",
    "    n_val = int(VAL_RATIO * n_total)\n",
    "\n",
    "    train_imgs = images[:n_train]\n",
    "    val_imgs = images[n_train:n_train + n_val]\n",
    "    test_imgs = images[n_train + n_val:]\n",
    "\n",
    "    #Copy images into split folders\n",
    "    for img in train_imgs:\n",
    "        shutil.copy(\n",
    "            os.path.join(cls_path, img),\n",
    "            os.path.join(OUT_DIR, \"train\", cls, img)\n",
    "        )\n",
    "\n",
    "    for img in val_imgs:\n",
    "        shutil.copy(\n",
    "            os.path.join(cls_path, img),\n",
    "            os.path.join(OUT_DIR, \"val\", cls, img)\n",
    "        )\n",
    "\n",
    "    for img in test_imgs:\n",
    "        shutil.copy(\n",
    "            os.path.join(cls_path, img),\n",
    "            os.path.join(OUT_DIR, \"test\", cls, img)\n",
    "        )\n",
    "\n",
    "print(\"Train / Validation / Test split completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059625dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'raw/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m IMG_SIZE = (\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)\n\u001b[32m      4\u001b[39m BATCH_SIZE = \u001b[32m32\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m train_ds = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mraw/train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m val_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mraw/val\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     image_size=IMG_SIZE,\n\u001b[32m     17\u001b[39m     batch_size=BATCH_SIZE,\n\u001b[32m     18\u001b[39m     shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m test_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mraw/test\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     image_size=IMG_SIZE,\n\u001b[32m     24\u001b[39m     batch_size=BATCH_SIZE,\n\u001b[32m     25\u001b[39m     shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Computer Vision/Plant Diseases Detection/pdd/lib/python3.11/site-packages/keras/src/utils/image_dataset_utils.py:265\u001b[39m, in \u001b[36mimage_dataset_from_directory\u001b[39m\u001b[34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, format, verbose)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    264\u001b[39m     seed = np.random.randint(\u001b[32m1e6\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m image_paths, labels, class_names = \u001b[43mdataset_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label_mode == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) != \u001b[32m2\u001b[39m:\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    278\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mWhen passing `label_mode=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`, there must be exactly 2 \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    279\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    280\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Computer Vision/Plant Diseases Detection/pdd/lib/python3.11/site-packages/keras/src/utils/dataset_utils.py:743\u001b[39m, in \u001b[36mindex_directory\u001b[39m\u001b[34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels == \u001b[33m\"\u001b[39m\u001b[33minferred\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    742\u001b[39m     subdirs = []\n\u001b[32m--> \u001b[39m\u001b[32m743\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m    744\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m path_module.isdir(path_module.join(directory, subdir)):\n\u001b[32m    745\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir.startswith(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'raw/train'"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# IMG_SIZE = (224, 224)\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     \"raw/train\",\n",
    "#     image_size=IMG_SIZE,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=True,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     \"raw/val\",\n",
    "#     image_size=IMG_SIZE,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "# test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     \"raw/test\",\n",
    "#     image_size=IMG_SIZE,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6165f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
